---
title: "Etude de la végétation de Mafragh"
author: "Aldric, Baptiste, Jeanne, Lucien, Lucile"
date: "2023-10-05"
output: pdf_document
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Une petite mise en contexte Ou se situe la plaine du Mafragh ?
Quelle est la végétation associée ?
Pourquoi relier sol et plantes est pertinent...

## Chargement des packages

```{r cars, include=FALSE}
rm(list=ls(all=TRUE))  # Reset the working environment

library(readxl)
#libraries for time series analyses
library(nlme)      #glm and gls
library(tidyverse) # for data cleaning, ordering, etc.

#libraries for spatial series analyses
library(spdep) #to extracted the neighbors is a spatial data
library(ade4)  #used for plotting spatial data
library(spatialreg) #used for spatial data modelling
library(gwrr)  #to run geographically weighted regression
library(ade4)
library(vegan)
library(ggplot2)
library(factoextra)
library(corrplot)
library(RVAideMemoire)
library(PerformanceAnalytics)
library(readxl)

require(questionr)
require(nnet)
require(aod)

require(car)
```

## Chargement des données

```{r pressure, include=FALSE}
file_path = "data_vegetation_french.xls"

flo = read_excel(file_path, sheet = "flo")
mil = read_excel(file_path, sheet = "mil", col_types = 'numeric')
coord = read_excel(file_path, sheet = "coord", col_types = 'numeric')
association = read_excel(file_path, sheet = "association")

flo_mil = cbind(flo, mil)
```

Nous récupérons ici le jeu de données afin de réaliser l'analyse.
\
Nous créons quatre data.frames afin d'obtenir les différents tableaux nécessaires à l'analyse :

-   "flo" = tableau d'abondance des espèces végétales par site (tableau de contingence)

-   "mil" = variables environnementales (pédologiques) par site (variables quantitatives uniquement)

-   "coord" = coordonnées GPS des différents sites

-   "association" = zonage du mileu d'étude en fonction d'associations végétales (variable qualitative)

# Exploration du jeu de données

## Représentation spatiale

```{r}
coord
plot(coord)
coord.knear4 = knearneigh(as.matrix(coord),4) #(A)
knn2nb(coord.knear4)
plot(knn2nb(coord.knear4), coord, add=TRUE) #(B)


ade4::s.label(coord, ylim=c(min(coord[,1])-50, max(coord[,1])+50) ,xlim=c(min(coord[,2])-50,max(coord[,2])+50),  clabel=0.6,cpoint=1,neig=nb2neig(knn2nb(coord.knear4)))
```

Ci-dessous, nous commençons à parcourir les données en étudiant les coordonnées géographiques des différents sites.

Le plot permet d'observer la répartition des points et aucune configuration régulière ne se détache (ex : root, queen, etc.)

Nous décidons d'étudier la répartition des points par l'étude de leur quatre plus proches voisins.
Pour cela nous extrayons les voisins (A), puis nous vérifions que les 97 sites sont dotés de quatre voisins ce qui est le cas puisque le nombre de lien est bien de 388 (97\*4)

Nous réalisons ensuite un plot afin de voir comment les points sont reliés entre eux (B)

##Représentation des voisins --\> on garde ou pas ?
pas exploité par la suite...

```{r}
#Gabriel :

veg.gab<-gabrielneigh(as.matrix(coord))
# you can represent it spatially with this function:
#s.label(coord,clabel=.5, cpoint=.1,neig=nb2neig(graph2nb(veg.gab)))

#Delaunay :
veg.tri<-tri2nb(coord)
# graphic representation:
#s.label(coord,clabel=0.6,cpoint=1,neig=nb2neig(veg.tri))
# synthetic view:
veg.tri

#Distance
veg.dnear<-dnearneigh(as.matrix(coord),0,30) #here we specify that ponds are connected if they are appart from less than 30m
# graphic representation:
#s.label(coord,clabel=0.6, cpoint=1,neig=nb2neig(veg.dnear))
# synthetic view:
veg.dnear #in that specific case: the ponds 4 and 31 are not connected to any other pond

par(mfrow=c(1,3))
s.label(coord,clabel=0, cpoint=.1,neig=nb2neig(graph2nb(veg.gab))) 
s.label(coord,clabel=0,cpoint=1,neig=nb2neig(veg.tri))
s.label(coord,clabel=0, cpoint=1,neig=nb2neig(veg.dnear))
```

## Analyses préliminaires

### Test et standardization

Avant de commencer l'analyse, il s'agit de tester l'homogénéité de la variance avec le test de Bartlett.
Les données sont ensuite standardizées de la façon suivante : La transformation d'Hellinger est appliquée aux données floristiques.
Cela permet notamment de pallier le problème lié à l'écart d'abondance entre plusieurs espèces.
Les données pédologique (mil) sont centrées et réduite car les unités des variables ne sont pas identiques.

```{r}
bartlett.test(flo)

#standardization methods : adapt to your own data
flo <- decostand(flo, "hellinger") #package vegan
mil= as.data.frame(scale(mil, center=TRUE, scale=TRUE))
```

Le test de Barlett confirme que nous nous trouvons en situation d'homocédasticité.
H0 correspond à la situation d'homogénité des variances et la p-value ici est inférieure à 2.2e-16 : rejet de H0\
La transformation par Helliger était donc nécessaire.

### Etude de la corrélation entre variables

#### Pour les données pédologiques

```{r}
M <- cor(mil)
par(mfrow=c(1,1))
corrplot(M, method = "number")
```

Il existe de rares corrélations entre variables, au seuil 0.7, Na+ est corrélé avec Conduct et Sable avec Argile.
Ce résultat n'est pas surprenant, comme le limon, le sable et l'argile donnent la texture du sol, ces trois variables sont corrélées.
Pour le moment, toutes les varibales sont concervées.
Il s'agira de vérifier s'il reste des corrélations dans les variables qui seront choisies lors de la création de modèle.

#### Pour les données floristiques

```{r}
M <- cor(flo)
corrplot(M, method = "number",type="upper") #pas de corrélation entre les espece.
```

Il n'y a pas de corrélation entre les différentes espèces.

#### Etudes des corrélations entre les données floristiques et pédologiques

```{r}
M <- cor(flo_mil)
corrplot(M, method = "square")  #ni entre esp et envrnt
```

Pas de corrélation entre les espèces et des données pédologiques.

Ces analyses préliminaires nous ont montrées que nous faisons face à de grands tableaux de valeurs mais présentant peu de corrélations entre variables.
Par la suite, nous allons nous pencher sur la corrélation spaciale

## Etude de l'autocorrélation spaciale

```{r}
geo = dist(xy) #(A.1)

chim = dist(scale(mil),method = "euclidian") #(A.2)

r1 = mantel.rtest(geo,chim,nrepet=1000) #(B)
r1 #(C)

plot(r1, main = "Mantel's test") #(D)
```

Pour cela, nous utilisons le test de Mansel qui permet de tester la présence d'autocorrélation spatiale sur des jeux de données avec de nombreuses variables et qui seront traités par la suite par des analyses multivariées.

Nous commençons par calculer les distances géographiques entre les sites et celles entre les variables quantitatives représentant l'environnement.
(A.1 & A.2)\

Ensuite, nous utilisons la fonction "mantel.rtest" pour simuler nrepet fois la correlation entre les deux matrices de distance précédemment calculé.
Cela va permettre d'obtenir une loi de distribution sur les fréquences de corrélation quand les couples de valeurs sont créés aléatoirement.
(B)\

La corrélation réelle observée est alors comparé à cette loi de distribution.
L'hypothèse H0 est que la correlation entre les deux matrices est nulle.
(C)

Nous observons ici que la p-value est de 2% ce qui signifie qu'il existe une réelle autocorrélation spatiale dans notre jeu de données.
Cela est également visible en réalisant le plot sur le test de Mantel.
(C & D)

**Nous allons donc nour diriger vers des analyses multivariées prenant en compte cette autocorrélation spatiale.**

# Etude statistique

## Selection des variables pertinententes

```{r}

###sélection des variables non redondantes (collinéarité)###
rdadoubs=rda(flo~.,mil) #CCA (A)
first=ordistep(rdadoubs,perm.max=500) #(B)
first #(C)


test=vif.cca(first) #(D)
test #(E)
 
mil2=mil[,c("Mg++", "K+", "Capa_Reten", "Altitude")] 
selected=as.data.frame(scale(mil2, center=TRUE, scale=TRUE)) #(F)

```

Le but du script ci-dessus est de séléctionner les variables environnementales pertinentes pour nos analyses.
En effet, garder l'ensemble des variables peut être lourd pour l'analyse et demande un nombre de sites très important.
La variance peut se retrouver éclater entre l'ensemble des variables.
De plus, une corrélation entre plusieurs variables a été démontrée précédemment.

Pour trouver les variables d'intérêt, nous allons créer un modèle complet, c'est-à-dire avec l'ensemble des variables environnementales (explicatives) (A), puis nous utilisons la fonction "ordistep" afin de faire une séléction de variables (B).
A chaque tour, la variable la moins significative est enlevée jusqu'obtenir uniquement des variables significatives.

Le résultat permet de fortement réduire le nombre de variables puisque seules quatre sont séléctionnées : "Mg++" ; "K+", "Capa_Reten" et "Altitude".
(C)

Avant de valider ces variables, il faut cependant vérifier qu'il n'existe pas de corrélation entre elles.
Pour cela, nous utilisons la Variance Inflation Factor (VIF) qui permet de tester la corrélation entre chaque variable par rapport à l'ensemble des autres présentes dans le modèle.
(D)

Si la valeur VIF est inférieure à 10 pour chaque variable, alors il est possible de conclure qu'il n'y a pas de corrélation entre elles.
C'est le cas ici (E)

Nous récupérons donc les variables environnementales séléctionnées.
(F)

## Partitionnement de variance

On réalise un partitionnement de variance pour étudier comment est distribuée la variance du tableau de comptage floristique en fonction des caractéristiques pédologiques du milieu et des cordonnées géographiques.

```{r}
partion_var <- varpart(flo,mil,coord)
plot(partion_var, bg=2:5)
```

Les données pédologiques expliquent, à elles seules 9% de la variance de la distribution floristique.
7% de cette variance est expliquée par les coordonnées géographique.
L'interaction entre pédologie et géographie explique 4% de la variance du tableau de comptage des espèces végétales.
On constate que la majorité de la variance (80%) des espèces végétales n'est pas expliquée par les données dont nous disposons.

Par la suite, nous allons exclure la dépendance spatiale en travaillant sur l'influence du milieu pédologique sur les communautés végétales.
Pour cela, nous allons réaliser une Analyse Partielle Canonique des Correspondances (pCCA).
En effet, nous avons un tableau de contingence qui peut être analysé par une AFC alors que le tableau de variables environnementales sera analysé par une ACP.
De plus, comme nous savons que l'environnement devrait expliquer l'abondance des espèces végétales, nous faison une analyse *a priori* et donc ne nous dirigeons pas vers une co-inertie.

--\> Mettre des légendes au graph au lieu de X1 et X2, écrire Milieu et Spacial...

## Partial Canonical Correspondence Analysis

L'Analyse Partielle Canonique des Correspondances est réalisée avec le package Vegan.

```{r}
ccap_flo=cca(flo,selected,coord,scan=F)
ccap_flo
```

L'inertie total de l'analyse correspond à 7.97.
Nous avons ensuite le détail de l'ensemble des partitionnements de variance.
"Conditionnal" correspond à la variance expliquée par les coordonnées géographiques et dont on veut "se débarrasser".
Cela correspond à une inertie de 0.70.
La partie "Constrained" est la partie qui nous intéresse puisque c'est la variance de nos espèces végétales liée au milieu.
On retrouve ici nos 9% soit une inertie de 0.71.
Enfin, la parite "Unconstrained" est la part lié aux résidus.
C'est donc 80% de l'inertie qui n'est pas expliquée par les tables de valeur dont nous disposons.

Nous nous intéressons donc principalement à la partie "Constrained".
Le premier axe représente environ 50% (0.35/0.7) de la variance expliquée par le milieu pédologique et 4% de la variance totale de la distribution floristique (voir CCA1 - constrained part).
Le deuxième axe représente lui 25% (0.18/0.7) de la variance contrainte et 2% de la partie totale.

La pCCA est testée à l'aide d'un test de permutation :

```{r}
anova.cca(ccap_flo)
```

Ici, 999 permutations des données ont été réalisées pour observer si le résultat de la pCCA n'était pas simplement dû à l'aléatoire.
Les résultats de la pCCA sont significatifs (pvalue = 0.001).
Cela signifie que notre pCCA ne peut pas être lié au hasard mais qu'il existe bien un lien entre nos différents tableaux.

Nous pouvons maintenant nous intéresser aux résultats de notre pCCA :

```{r}
ccap_flo$CCA$v #(A)


ccap_flo$CCA$biplot #(B)


MVA.synt(ccap_flo) #conditionnel = 8.78 c'est xy, constrained = 8.94 c'est mil


```

Premièrement, nous observons le score des espèces végétales pour chaque axe.
(A)

Nous faisons la même observation pour le score des variables environnementales.
(B)

L'altitude est fortement corrélée négativement au premier axe.
La capacité de rétention est fortement corrélée négativement au deuxième axe.



```{r}
#plot the pCCA
par(mfrow=c(1,2))
plot(ccap_flo,scaling=1)
plot(ccap_flo,scaling=2)
plot(ccap_flo,scaling=3)

par(mfrow=c(1,1))
plot(ccap_flo, type="n")
text(ccap_flo, col="blue",cex = 0.75)
text(ccap_flo, dis="cn",col="black",cex = 1.2)
plot(ccap_flo, type="n")
text(ccap_flo, dis="cn",col="black",cex = 1)
text(ccap_flo, "species", col="blue", cex=0.8)

```

  ##JE NE COMPREND PAS POURQUOI ON A PAS LES NUMEROS DES SITES QUI APPARAISSENT SUR LES GRAPHES "scaling" CAR DU COUP ON NE PEUT PAS INTERPRETER....

# Création d'un modèle à vocation prédictive pour la classe de Association

## Selection du meilleur modèle

```{r}
asso.mlogit = multinom(association$association~.,mil) #modèle multinomial complet
asso = multinom(association$association~1,mil) #modèle multinomial null
beta = coef(asso.mlogit)

model = step(asso, direction = "both", scope = formula(asso.mlogit))
```

Grace à la selection du meilleur modèle, obtenu en minimisant l'AIC, on s'arrête sur les variables K+, Altitude, Capa_Reten et Sable.

```{r}
asso.selected = mil[, c("K+", "Altitude",  "Capa_Reten", "Sable")]
asso.select.mlogit = multinom(association$association~.,asso.selected)
```

On vérifie la multicollinéarité :

```{r}
vif(asso.select.mlogit)
```

La valeur du VIF pour la variable Sable s'élève à 1933, c'est beaucoup trop !
Il s'agira d'enlever cette variable :

```{r}
asso.selected.no.sand = mil[, c("K+", "Altitude",  "Capa_Reten")]
asso.selected.no.sand$K = asso.selected.no.sand$"K+"
asso.selected.no.sand = asso.selected.no.sand[-1]
model_final = multinom(association$association~.,asso.selected.no.sand)

summary(model_final)

vif(model_final) 
```

Désormais, mode_final ne présentente pas de soucis de multicollinéarité.
Nous allons l'utiliser pour réaliser de la prédiction de classe.

Le modèle peut être représenté par un système de 6 équations batties comme la suivante, avec i variant entre 2 et 7.

\$ i=2,...,7\$

\$ \frac{{P(Y = C_{i} | X_{1} = x_{1}, X_{2} = x_{2}, X_{3} = x_{3})}}{{P(Y = C_{1} | x_{1}, X_{2} = x_{2}, X_{3} = x_{3})}} = \beta*{0i} +* \beta{1i} \cdot X\_{1} + \beta*{2i}* \cdot X{2} + \beta*{3i}* \cdot X{3} \$

Avec $\beta_{0}$ est l'intercept, $\beta_{1}$ est le coefficient d'altitude, $\beta_{2}$ est le coefficient de capacité de rétention et $\beta_{3}$ le coefficient de concentration en K+.

## Prédictions

```{r}
proba = predict(model_final, newdata = data.frame(asso.selected.no.sand), type="class")
confusion = table(association$association,proba,dnn=list("Observed","Predicted"))
confusion

## il faudrait la mettre en couleur mais j'ai pas trouvé...

```

--\> mettre en couleur cette matrice
